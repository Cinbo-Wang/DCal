% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/DCal.R
\name{DCal.mean_treat}
\alias{DCal.mean_treat}
\title{Estimation of E[Y(1)] from observational data using Double Calibration Estimator.}
\usage{
DCal.mean_treat(
  X,
  Y,
  W,
  Y.family = c("gaussian", "binomial")[1],
  B = 6,
  is.scale = TRUE,
  r1_init = NULL,
  pi_init = NULL,
  alpha = 0.9,
  is.parallel = FALSE,
  core_num = NULL,
  ratio_violate_dcal = 0.01
)
}
\arguments{
\item{X}{The n by p input data matrix.}

\item{Y}{The n dimensional observed response.}

\item{W}{The n dimensional binary vector indicating treatment assignment.}

\item{Y.family}{Response type. A character string representing one of the built-in families, including 'gaussian' and 'binomial'.}

\item{B}{The number of iterations for random splits for cross-fitting.}

\item{is.scale}{Whether or not to scale the input data matrix.}

\item{r1_init}{Optional n dimensional vector of an initial estimate of E[Y_i |
X_i, T_i=1] for i = 1, ..., n. The default is NULL.}

\item{pi_init}{Optional n dimensional vector of an initial estimate of E[W_i |
X_i] for i = 1, ..., n. The default is NULL.}

\item{alpha}{The elastic net mixing parameter, with \(0 \eqn{\leq} alpha \eqn{\leq} 1\).}

\item{is.parallel}{Whether to perform parallel computation. Default is False.}

\item{core_num}{Number of cores used for parallel computation.}

\item{ratio_violate_dcal}{The maximum allowable ratio of violations in inequations during the Double Calibrated step. The default value is 0.01.}
}
\value{
\item{ATE_sc}{Single calibation estimation of E[Y(1)] averaged over B random splits.}
\item{ATE_sc_var}{Estimated variance of the ATE_sc averaged over B random splits.}
\item{ATE_dc}{Double calibation estimation of E[Y(1)] averaged over B random splits.}
\item{ATE_dc_var}{Estimated variance of the ATE_dc averaged over B random splits.}
\item{ATE_mat}{A matrix containing ATE_sc, ATE_sc_var, ATE_dc and ATE_dc_var in each random split.}
}
\description{
Estimation of E[Y(1)] from observational data using Double Calibration Estimator.
}
\examples{
\dontrun{
# Sparse OR, dense nonlinear PS--------
p = 400; s_or = 10; n = 200;rho=0.9;rd_num = 1
Sigma_X <- matrix(0,p,p)
for(i in 1:p){
  for(j in 1:p){
    Sigma_X[i,j] <- rho ** abs(i-j)
  }
}

X <- MASS::mvrnorm(n=n,mu=rep(0,p),Sigma = Sigma_X)
# dense propensity model
Xf <- X[,1:4]
Xf[,1] <- exp(0.5 * X[,1])
Xf[,2] <- 10 + X[,2] / (1 + exp(X[,1]))
Xf[,3] <- (0.05 * X[,1] * X[,3] + 0.6)**2
Xf[,4] <- (X[,2] + X[,4] + 10)**2

gamma_true <- rep(0,p)
for(j in 1:p){
  gamma_true[j] <-  1/j
}
gamma_true <- gamma_true / norm(gamma_true,type='2')

lp <- scale(Xf[,1:4]) \%*\% c(1,-1/2,1/4,-1/8) + X \%*\% gamma_true
pi_W <- 1/(1+exp(-lp))
pi_W <- pmin(pmax(pi_W, 0.05), 0.95)
W <- rbinom(n = n,size=1,p=pi_W)

# sparse linear OR
beta_true <- rep(0,p)
act_loc <- 1:s_or # Confounder
beta_true[act_loc] <- runif(s_or,1,2)
beta_true <-  beta_true / norm(beta_true,type='2')
potential_outcome_treat <- X \%*\% beta_true + 1
potential_outcome_control <- X \%*\% beta_true - 1
Y <- potential_outcome_treat * W + potential_outcome_control * (1-W) + rnorm(n,0,1)
tau_treat <- mean(potential_outcome_treat)

mean_treat_dcal_ls <- DCal.mean_treat(X,Y,W,B=6,r1_init = NULL,pi_init = NULL,
                     is.scale = FALSE,Y.family = 'gaussian',alpha = 0.9, is.parallel=FALSE)

mean_treat_dcal_ls
}
}
\references{
Lin Liu, and Yuhao Wang. (2023) \emph{Root-n consistent semiparametric learning with
high-dimensional nuisance functions under minimal sparsity.} \url{https://doi.org/10.48550/arXiv.2305.04174}
}
\author{
Xinbo Wang
}
